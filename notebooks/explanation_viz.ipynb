{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Visualization Notebook\n",
    "Scroll down to the bottom of the notebook to access the visualization code. You will need to provide a log\n",
    "directory to a trained protonet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483ad603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from typing import Union\n",
    "\n",
    "import os.path as osp\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib import cm\n",
    "\n",
    "import torch\n",
    "\n",
    "from torchvision.transforms import functional as F\n",
    "from skimage.transform import resize\n",
    "\n",
    "import numpy as np\n",
    "from numpy import unravel_index\n",
    "\n",
    "try:\n",
    "    import pixpnet\n",
    "except ImportError:\n",
    "    import sys\n",
    "\n",
    "    sys.path.append('..')\n",
    "\n",
    "    import pixpnet\n",
    "finally:\n",
    "    from pixpnet.data import get_datasets\n",
    "    from pixpnet.data import get_metadata\n",
    "    from pixpnet.protonets.lit_model import ProtoLitModel\n",
    "    from pixpnet.protonets.utils import load_config_and_best_model\n",
    "    from pixpnet.symbolic.models import compute_rf_data\n",
    "    from pixpnet.utils import parse_config_file\n",
    "    from pixpnet.utils_torch import slices_to_bboxes\n",
    "    from pixpnet.utils_torch import take_rf_from_bbox\n",
    "    from pixpnet.utils_torch import take_rf\n",
    "\n",
    "sns.set(\n",
    "    style='whitegrid',\n",
    "    font_scale=2.5,\n",
    ")\n",
    "from matplotlib import rc\n",
    "\n",
    "rc('font', **{\n",
    "    'family': 'serif',\n",
    "    'sans-serif': ['Times']\n",
    "})\n",
    "rc('text', usetex=True)\n",
    "\n",
    "\n",
    "def projected_prototypical_samples(metadata, model, ds_train, rf_layer):\n",
    "    corresponding_sample_idxs = model.model.corresponding_sample_idxs\n",
    "    min_fmap_idxs = model.model.min_fmap_idxs\n",
    "\n",
    "    num_prototypes = model.model.num_prototypes\n",
    "    assert len(corresponding_sample_idxs) == num_prototypes\n",
    "    assert len(min_fmap_idxs) == num_prototypes\n",
    "\n",
    "    projected_samples = []\n",
    "    projected_patches = []\n",
    "    projected_patch_slices = []\n",
    "\n",
    "    for j in range(num_prototypes):\n",
    "        idx = corresponding_sample_idxs[j]\n",
    "        if idx == -1:\n",
    "            print(f'prototype {j} has no corresponding sample!')\n",
    "            projected_samples.append(None)\n",
    "            projected_patches.append(None)\n",
    "        else:\n",
    "            idx_, x, y = ds_train[idx]\n",
    "            assert idx_ == idx, (idx_, idx)  # BIST\n",
    "\n",
    "            (fmap_h_start, fmap_h_end,\n",
    "             fmap_w_start, fmap_w_end) = min_fmap_idxs[j]\n",
    "            rf_feat = take_rf(rf_layer, fmap_h_start, fmap_h_end,\n",
    "                              fmap_w_start, fmap_w_end)\n",
    "\n",
    "            patch = rf_feat.take_from(\n",
    "                x[None], all_channels=True).squeeze(axis=0)\n",
    "            patch = rescale_image(patch, metadata.input_size)\n",
    "            patch = patch.numpy().transpose(1, 2, 0)\n",
    "            projected_patches.append(patch)\n",
    "\n",
    "            sample = rescale_image(x, metadata.input_size)\n",
    "            sample = sample.numpy().transpose(1, 2, 0)\n",
    "            projected_samples.append(sample)\n",
    "            projected_patch_slices.append(rf_feat.as_slices(\n",
    "                all_channels=True))\n",
    "\n",
    "    return projected_samples, projected_patches, projected_patch_slices\n",
    "\n",
    "\n",
    "def rescale_image(img: Union[torch.Tensor, np.ndarray, Tuple], meta_size: int,\n",
    "                  max_size: int = 256):\n",
    "    if meta_size < max_size:\n",
    "        return img\n",
    "    scaler = max_size / meta_size\n",
    "    if isinstance(img, torch.Tensor):\n",
    "        c, h, w = img.size()\n",
    "        return F.resize(img, [round(h * scaler), round(w * scaler)])\n",
    "    elif isinstance(img, np.ndarray):\n",
    "        h, w, c = img.shape\n",
    "        return resize(img, [round(h * scaler), round(w * scaler)])\n",
    "    elif isinstance(img, tuple):  # bbox\n",
    "        (x, y), width, height = img\n",
    "        return (x * scaler, y * scaler), width * scaler, height * scaler\n",
    "    else:\n",
    "        raise NotImplementedError(type(img))\n",
    "\n",
    "\n",
    "def get_last_layer_coef(readout_type, last_layer, y_i, proto_idx, proto_class):\n",
    "    if last_layer is None:\n",
    "        return None\n",
    "    if readout_type == 'linear':\n",
    "        coef = last_layer.weight[y_i, proto_idx]\n",
    "    elif readout_type == 'sparse':\n",
    "        if proto_class != y_i:\n",
    "            coef = 0\n",
    "        else:\n",
    "            proto_idx_group = proto_idx % last_layer.groups\n",
    "            coef = last_layer.weight[y_i, proto_idx_group]\n",
    "    elif readout_type == 'proto':\n",
    "        coef = 1 if y_i == proto_class else 0\n",
    "    else:\n",
    "        raise NotImplementedError(readout_type)\n",
    "    return coef\n",
    "\n",
    "\n",
    "def compute_contributions_sample_proto2patch(readout_type, last_layer, y_i,\n",
    "                                             proto_sims_i):\n",
    "    if readout_type == 'linear':\n",
    "        contributions = last_layer.weight[y_i] * proto_sims_i\n",
    "    elif readout_type == 'sparse':\n",
    "        proto_sims_grouped = proto_sims_i.reshape(\n",
    "            last_layer.groups, last_layer.in_features_per_group)\n",
    "        contributions = torch.zeros_like(proto_sims_i)\n",
    "        contributions[y_i, :] = (\n",
    "                last_layer.weight[y_i] * proto_sims_grouped[y_i, :])\n",
    "        contributions = contributions.flatten()\n",
    "    elif readout_type == 'proto':\n",
    "        proto_sims_grouped = proto_sims_i.reshape(\n",
    "            last_layer.groups, last_layer.in_features_per_group)\n",
    "        contributions = torch.zeros_like(proto_sims_grouped)\n",
    "        contributions[y_i, :] = proto_sims_grouped[y_i, :]\n",
    "        contributions = contributions.flatten()\n",
    "    else:\n",
    "        raise NotImplementedError(readout_type)\n",
    "    return contributions\n",
    "\n",
    "\n",
    "def min_max_norm(arr, min=None, max=None, inplace=True):\n",
    "    if not inplace:\n",
    "        arr = arr.copy()\n",
    "    # min-max normalize to 0-1\n",
    "    arr -= arr.min() if min is None else min\n",
    "    arr /= arr.max() if max is None else (max - min)\n",
    "    return arr\n",
    "\n",
    "\n",
    "def overlay_heatmap(img: np.ndarray,\n",
    "                    heatmap: np.ndarray,\n",
    "                    heatmap_weight: float = 0.5,\n",
    "                    cmap: str = 'jet',\n",
    "                    data_format='channels_first'):\n",
    "    assert img.ndim == 3, img.shape\n",
    "    if data_format == 'channels_first':\n",
    "        img = img.transpose((1, 2, 0))\n",
    "        if heatmap.ndim == 3:\n",
    "            heatmap = heatmap.transpose((1, 2, 0))\n",
    "    if heatmap.ndim == 3:\n",
    "        assert heatmap.shape[2] == 1, heatmap.shape\n",
    "        heatmap = heatmap.squeeze(axis=2)\n",
    "    else:\n",
    "        assert heatmap.ndim == 2, heatmap.shape\n",
    "    cmap = cm.get_cmap(cmap)\n",
    "    overlaid = (\n",
    "            cmap(heatmap)[:, :, :3] * heatmap_weight +\n",
    "            img * (1. - heatmap_weight)\n",
    "    )\n",
    "    return overlaid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367da00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savefig(logdir: str, prefix: str, fig: Union[plt.Figure, sns.FacetGrid],\n",
    "            show: bool = False, save: bool = True):\n",
    "    basenames = []\n",
    "    logdir_running = logdir\n",
    "    subdir_count = 0\n",
    "    while subdir_count < 3:\n",
    "        logdir_running, basename = osp.split(logdir_running)\n",
    "        if basename:\n",
    "            basenames.append(basename)\n",
    "            subdir_count += 1\n",
    "        if not logdir_running:\n",
    "            break\n",
    "    basenames = '_'.join(reversed(basenames))\n",
    "    # append basenames string so there are unique filenames when uploading\n",
    "    #  figures to things where filename conflicts are bad\n",
    "    save_path = osp.join(logdir, 'results', f'{prefix}_{basenames}.pdf')\n",
    "    if save:\n",
    "        print(f'Saving to \"{save_path}\"')\n",
    "        fig.savefig(save_path)\n",
    "    if show is True or (isinstance(show, str) and prefix.startswith(show)):\n",
    "        plt.show(block=True)\n",
    "    if isinstance(fig, sns.FacetGrid):\n",
    "        plt.close(fig.fig)\n",
    "    else:\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6046c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain(logdir, metadata, model, sample_norm, sample, y, rf_layer,\n",
    "            projected_patches, sample_id, k=11, sort='contributions',\n",
    "            plot=True, save=True):\n",
    "    \"\"\"\"\"\"\n",
    "    class_specific = model.model.class_specific\n",
    "    prototype_class_identity = model.model.prototype_class_identity\n",
    "    proto_layer_stride = model.model.prototype_layer_stride\n",
    "    n_prototypes, _, proto_h, proto_w = model.model.prototype_shape\n",
    "    if k is None:\n",
    "        k = n_prototypes\n",
    "    last_layer = model.model.last_layer\n",
    "    readout_type = model.model.readout_type\n",
    "\n",
    "    with torch.no_grad():\n",
    "        result = model(sample_norm[None].to(model.device),\n",
    "                       return_features=True)\n",
    "    logits = result['logits']\n",
    "    proto_dists = result['distances']\n",
    "    min_dist_idxs = result['min_dist_idxs']\n",
    "    proto_max_sims = result['max_similarities']\n",
    "\n",
    "    preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "    contributions = compute_contributions_sample_proto2patch(\n",
    "        readout_type, last_layer, preds[0], proto_max_sims[0])\n",
    "\n",
    "    if sort == 'contributions':\n",
    "        sort_idxs = torch.argsort(contributions, descending=True)\n",
    "    elif sort == 'similarity':\n",
    "        sort_idxs = torch.argsort(proto_max_sims[0], descending=True)\n",
    "    elif not sort:\n",
    "        sort_idxs = torch.arange(len(contributions))\n",
    "    else:\n",
    "        raise ValueError(f'sort = {sort}')\n",
    "    sample_npy = sample.numpy()\n",
    "\n",
    "    ncols = 5\n",
    "    scale = 3\n",
    "    fig, axes = plt.subplots(k, ncols, squeeze=False,\n",
    "                             figsize=(ncols * scale, k * scale))\n",
    "\n",
    "    pred_lab = preds[0]\n",
    "    y_lab = y\n",
    "    if metadata.label_names is not None:\n",
    "        pred_lab = metadata.label_names[pred_lab]\n",
    "        y_lab = metadata.label_names[y]\n",
    "\n",
    "    # PxHxW\n",
    "    sample_heat_map_max_all = model.model.pixel_space_map(\n",
    "        sample_norm.to(model.device), proto_dists, sigma_factor=1.)[0].cpu().numpy()\n",
    "\n",
    "    for j, axes_j in enumerate(axes):\n",
    "        j_adjust = sort_idxs[j]\n",
    "\n",
    "        projected_patch = projected_patches[j_adjust]\n",
    "\n",
    "        fmap_h_start, fmap_w_start = unravel_index(\n",
    "            min_dist_idxs[:, j_adjust].item(), proto_dists.shape[2:])\n",
    "        # retrieve the corresponding feature map patch\n",
    "        rf_feat = take_rf_from_bbox(rf_layer, fmap_h_start, fmap_w_start,\n",
    "                                    proto_h, proto_w, proto_layer_stride)\n",
    "        sample_patch = rf_feat.take_from(\n",
    "            sample_npy[None], all_channels=True).squeeze(axis=0)\n",
    "\n",
    "        sample_heat_map_max = sample_heat_map_max_all[j_adjust][None]\n",
    "        sample_heat_map_max = min_max_norm(sample_heat_map_max)\n",
    "        sample_heat_map_max_overlaid = overlay_heatmap(\n",
    "            sample_npy, sample_heat_map_max, heatmap_weight=.4)\n",
    "\n",
    "        bboxes_sample = slices_to_bboxes(rf_feat.as_slices(all_channels=True))\n",
    "\n",
    "        if class_specific:\n",
    "            proto_class = torch.argmax(\n",
    "                prototype_class_identity[j_adjust]).item()\n",
    "            if metadata.label_names is not None:\n",
    "                proto_class = metadata.label_names[proto_class]\n",
    "            proj_extra = f'\\n{proto_class}'\n",
    "        else:\n",
    "            proj_extra = ''\n",
    "\n",
    "        contrib_str = f' = {contributions[j_adjust]:.3g}'\n",
    "        print(f'Predicted: {pred_lab}  |  Actual: {y_lab}')\n",
    "        print(proj_extra)\n",
    "        for ax, (patch, title, bboxes) in zip(axes_j, (\n",
    "                # The test sample (full w/ patch bbox)\n",
    "                (rescale_image(sample_npy.transpose(1, 2, 0),\n",
    "                               metadata.input_size), 'Sample', bboxes_sample),\n",
    "                # Pushed/projected training sample (patch)\n",
    "                (projected_patch, f'Prototype', None),\n",
    "                # The test sample (patch)\n",
    "                (rescale_image(sample_patch.transpose(1, 2, 0),\n",
    "                               metadata.input_size),\n",
    "                 f'Corresponding\\nImage Patch', None),\n",
    "                (rescale_image(sample_heat_map_max_overlaid,\n",
    "                               metadata.input_size),\n",
    "                 'Overlaid Heat Map', bboxes_sample),\n",
    "                (contrib_str, 'Contribution', None),\n",
    "        )):\n",
    "            if isinstance(patch, str):\n",
    "                ax.text(0, 0, patch, va='center', ha='center')\n",
    "                ax.set_xlim(-3, 3)\n",
    "                ax.set_ylim(-3, 3)\n",
    "            elif patch is not None:\n",
    "                kwargs = {}\n",
    "                if patch.shape[2] == 1:\n",
    "                    kwargs['cmap'] = 'jet'\n",
    "                ax.imshow(patch, **kwargs)\n",
    "            if bboxes is not None:\n",
    "                for bbox in bboxes:\n",
    "                    bbox = rescale_image(bbox, metadata.input_size)\n",
    "                    rect = patches.Rectangle(*bbox, linewidth=2,\n",
    "                                             edgecolor='r',\n",
    "                                             facecolor='none')\n",
    "                    ax.add_patch(rect)\n",
    "            if j == 0:\n",
    "                ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    topk = '' if k is None else f'_top{k}'\n",
    "    sort_str = ('_' + sort) if sort else ''\n",
    "    # Uncomment to save figure\n",
    "    # savefig(logdir, f'explanation{sort_str}_{sample_id}{topk}', fig, show=plot,\n",
    "    #         save=save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# To Run\n",
    "Replace `logdir` with the path to your log directory (relative to the notebook). A template format is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb2ab3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = '/path/to/logs/protonet/dataset/protonet/timestamp'\n",
    "\n",
    "config, model = load_config_and_best_model(logdir)\n",
    "model.eval()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "config.dataset.val_size = 0\n",
    "config.debug = False\n",
    "print('get unnormalized datasets')\n",
    "_, ds_train, _, ds_test = get_datasets(config, normalize=False)\n",
    "print('get normalized datasets')\n",
    "_, _, _, ds_test_norm = get_datasets(config, normalize=True)\n",
    "\n",
    "metadata = get_metadata(config)\n",
    "\n",
    "print('compute rf data')\n",
    "_, rf_data = compute_rf_data(config.model.feature_extractor,\n",
    "                             metadata.input_size,\n",
    "                             metadata.input_size,\n",
    "                             num_classes=1)\n",
    "assert model.model.features.last_module_name == config.model.feature_layer\n",
    "rf_layer = rf_data[model.model.features.last_module_name]\n",
    "rf_hcc_lens = [len(hcc) for hcc in rf_layer.flat]\n",
    "im_size = metadata.input_size * metadata.input_size\n",
    "print(f'mean/max/min rf: {100 * np.mean(rf_hcc_lens) / im_size:.2f}% / '\n",
    "      f'{100 * np.max(rf_hcc_lens) / im_size:.2f}% / '\n",
    "      f'{100 * np.min(rf_hcc_lens) / im_size:.2f}%')\n",
    "\n",
    "print('project prototypical samples')\n",
    "with torch.no_grad():\n",
    "    (projected_samples, projected_patches,\n",
    "     projected_patch_slices) = projected_prototypical_samples(\n",
    "        metadata, model, ds_train, rf_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a9bfb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot = True\n",
    "save = True\n",
    "\n",
    "idxs_to_explain = torch.randperm(len(ds_test))[:10]\n",
    "\n",
    "for sort in ['contributions']:\n",
    "    for idx in idxs_to_explain:\n",
    "        print(f'Explain by {sort} for idx={idx}')\n",
    "        if hasattr(idx, 'item'):\n",
    "            idx = idx.item()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            explain(\n",
    "                logdir, metadata, model, ds_test_norm[idx][0],\n",
    "                ds_test[idx][0], ds_test[idx][1], rf_layer,\n",
    "                projected_patches, f'{idx}', sort=sort, plot=plot,\n",
    "                save=save, k=4,\n",
    "            )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngn",
   "language": "python",
   "name": "ngn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
